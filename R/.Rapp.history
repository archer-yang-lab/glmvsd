library(HDtweedie)
example(HDtweedie)
install.packages("gcdnet")
example("gcdnet")
## The file has code for rejection sampling examples#
#
###########################################################
##  Example 1, generate a realization of X ~ N(0,1)#
##  with rejection sampling using the Cauchy trial density.#
set.seed(5)#
accept=FALSE#
k=0#
while(!accept)#
{#
  k=k+1#
  ## generate realization of U_1, U_2 iid Unif(0,1)#
  u=runif(2)#
  ## generate realization of Z ~ Cauchy#
  z=tan(pi*(u[1]-0.5))#
  ## Check if the accept event occured#
  accept= u[2] <= exp(-0.5*z^2)*(1+z^2)*exp(1/2)*0.5#
}#
#
## the number of iterations is to is k:#
k#
#
## the accepted realization is#
z#
################################################### #
##  Example 2, generate a realization of #
##  X_1,..., X_n iid N(0,1) with rejection sampling#
##  using the Cauchy trial density.#
set.seed(5)#
#
n=1000#
#
## x.list is the vector that stores #
## realization of X_1,..., X_n#
x.list=rep(0, n)#
#
## k.list is the vector of#
## the number of iterations it took for #
## rejection sampling to accept, one for #
## each element in x.list#
k.list=rep(0, n)#
#
for(i in 1:n)#
{#
  accept=FALSE#
  k=0#
  while(!accept)#
  {#
    k=k+1#
    ## generate realization of U_1, U_2 iid Unif(0,1)#
    u=runif(2)#
    ## generate realization of Z ~ Cauchy#
    z=tan(pi*(u[1]-0.5))#
    ## Check if the accept event occured#
    accept= u[2] <= exp(-0.5*z^2)*(1+z^2)*exp(1/2)*0.5#
  }#
  x.list[i]=z#
  k.list[i]=k#
}#
#
## compare the sample quantiles to the standard normal quantiles#
qqplot(qnorm(ppoints(length(x.list))), x.list)#
abline(0,1)#
## generate n iid draws from N(0,1) with Box Muller:#
n=1e4#
## suppose n is even#
u1=runif(n/2)#
u2=runif(n/2)#
tmp=sqrt(-2*log(u1))#
x1=tmp*cos(2*pi*u2)#
x2=tmp*sin(2*pi*u2)#
x=c(x1,x2)#
## compare the sample quantiles to the standard normal quantiles#
qqplot(qnorm(ppoints(length(x))), x)#
abline(0,1)#
#
## generate approximate iid draws from N(0,1) using CLT:#
n=1e4#
z=apply(matrix(runif(n*12), nrow=n, ncol=12), 1, sum) - 6#
## compare the sample quantiles to the standard normal quantiles#
qqplot(qnorm(ppoints(length(z))), z)#
abline(0,1)#
################################################### #
##  Example 3, generate a realization of #
##  X_1,..., X_n iid TruncatedNormal(mu, sigma^2) #
##  with rejection sampling#
##  using the N(mu, sigma^2) trial density.#
mu=5#
sigma=3#
a=0#
b=10#
#
set.seed(5)#
n=1000#
## x.list is the vector that stores #
## realization of X_1,..., X_n#
x.list=rep(0, n)#
#
## k.list is the vector of#
## the number of iterations it took for #
## rejection sampling to accept, one for #
## each element in x.list#
k.list=rep(0, n)#
#
for(i in 1:n)#
{#
  accept=FALSE#
  k=0#
  while(!accept)#
  {#
    k=k+1#
    ## generate realization of Z~N(mu,sigma^2)#
    z=rnorm(1, mean=mu, sd=sigma)#
    ## check if the acceptance event occured#
    accept=(a <= z) & (z <= b )#
  }#
  x.list[i]=z#
  k.list[i]=k#
}#
################################################### #
##  Example 4, generate a realization of #
##  X_1,..., X_n iid Gamma(alpha, beta=1), alpha > 1.#
##  with rejection sampling#
##  using an unnamed trial density.#
alpha=1.2#
#
set.seed(25)#
n=1000#
## x.list is the vector that stores #
## realization of X_1,..., X_n#
x.list=rep(0, n)#
#
## k.list is the vector of#
## the number of iterations it took for #
## rejection sampling to accept, one for #
## each element in x.list#
k.list=rep(0, n)#
#
lambda=sqrt(2*alpha-1)#
lambda.inv=1/lambda#
#
alpha.lambda.expr=-log(4) + alpha - (lambda+alpha)*log(alpha)#
alpha.to.lambda=alpha^lambda#
alpha.minus.lambda = alpha-lambda#
for(i in 1:n)#
{#
  accept=FALSE#
  k=0#
  while(!accept)#
  {#
    k=k+1#
    ## generate realization of U_1, U_2 iid Unif(0,1)#
    u=runif(2)#
    ## generate realization of Z from the unnamed distribution#
    z=alpha*(u[1]/(1-u[1]))^lambda.inv#
    ## check if the acceptance event occured#
    logf.over.tilde.g = alpha.minus.lambda*log(z) - z #
    logf.over.tilde.g = logf.over.tilde.g + 2*log(alpha.to.lambda + z^lambda) + alpha.lambda.expr#
    accept= log(u[2]) < logf.over.tilde.g#
  }#
  x.list[i]=z#
  k.list[i]=k#
}#
#
## compare the sample quantiles to the Gamma(alpha, beta=1) quantiles#
qqplot(qgamma(ppoints(length(x.list)), shape=alpha, scale=1), x.list)#
abline(0,1)#
################################################### #
##  Example 5, #
set.seed(5)#
#
n=500#
mu=1+10*runif(1)#
## generate n iid draws from Exp(mu)#
x.list=-mu*log(runif(n))#
#
nm=1e3#
## m.list is the vector that stores #
## the iid draws from (M|X_1=x_1,...X_n=x_n)#
m.list=rep(0, nm)#
#
## k.list is the vector of#
## the number of iterations it took for #
## rejection sampling to accept, one for #
## each element in m.list#
k.list=rep(0, nm)#
#
xbar=mean(x.list)#
if( (1 <= xbar) & (xbar <= 11) )#
{  #
  const=-n*log(xbar)-n #
} else if ( xbar > 11)#
{#
  const=-n*log(11)-n*xbar/11#
} else#
{#
  const=-n*xbar#
}#
for(i in 1:nm)#
{#
  accept=FALSE#
  k=0#
  while(!accept)#
  {#
    k=k+1#
    ## generate realization of U_1, U_2 iid Unif(0,1)#
    u=runif(2)#
    ## generate realization of Z from the Unif(1,11)#
    z=1+10*u[1]#
    ## check if the acceptance event occured #
    accept= log(u[2]) <  (-n*log(z) - n*xbar / z - const)#
  }#
  m.list[i]=z#
  k.list[i]=k#
}#
#
plot(density(m.list))
1+2
1+2#
1+1
1+2#
1+1#
#
1+1
set.seed(1)
set.seed(1)#
n=100#
p=8#
#
## Define the true parameter values#
## the error precision#
omega.star=2
source("rlasso.r")
set.seed(1)#
n=100#
p=8
## compute the square root of the covariance
## matrix for the random predictors
eo=eigen(sigma, symmetric=TRUE)
sigma.sqrt=eo$vec%*%diag(eo$val^0.5)%*%t(eo$vec)
## generate a realization of the random predictor matrix
## the rows are independent draws from N_{p-1}(0, sigma)
predictor.matrix=matrix(rnorm(n*(p-1)), nrow=n, ncol=(p-1))%*%sigma.sqrt
## create the design matrix
X=cbind(1, predictor.matrix)
## generate the response vector
y=X%*%beta.star + rnorm(n, mean=0, sd=sqrt(1/omega.star))
##  Compare three functions to compute the solution:
##  pick a positive value for lam
lam=0.5
1+1
source("binomialfit.R", chdir = TRUE)#
source("tools.R", chdir = TRUE)#
source("modelfit.R", chdir = TRUE)#
library(glmnet)#
library(ncvreg)#
# library(glmvsd)#
n.sim <- 100#
n <- 1000 #
p <- 8#
#
b <- c(24, 12, 0, 0, 16, 0, 0, 0) #
true_m <- (1 - (b == 0))#
no_checkmod <- 3#
x <- matrix(rnorm(n*p), n, p)#
# x = matrix(rnorm(n*p), n, p) %*% sqrtmat#
feta <- x %*% b #
fprob <- ifelse(feta < 0, exp(feta)/(1+exp(feta)), 1/(1 + exp(-feta)))#
y <- rbinom(n, 1, fprob)#
#
model_check <- matrix(NA, nrow=no_checkmod, ncol=p,#
                      dimnames=list(c("lasso","mcp","scad"),#
                                    paste("V",seq(p),sep="")))#
## model_check from lasso
source("binomialfit.R", chdir = TRUE)#
source("tools.R", chdir = TRUE)#
source("modelfit.R", chdir = TRUE)#
library(glmnet)#
library(ncvreg)#
# library(glmvsd)#
n.sim <- 100#
n <- 1000 #
p <- 8#
#
b <- c(24, 12, 0, 0, 16, 0, 0, 0) #
true_m <- (1 - (b == 0))#
no_checkmod <- 3#
x <- matrix(rnorm(n*p), n, p)#
# x = matrix(rnorm(n*p), n, p) %*% sqrtmat#
feta <- x %*% b #
fprob <- ifelse(feta < 0, exp(feta)/(1+exp(feta)), 1/(1 + exp(-feta)))#
y <- rbinom(n, 1, fprob)#
#
model_check <- matrix(NA, nrow=no_checkmod, ncol=p,#
                      dimnames=list(c("lasso","mcp","scad"),#
                                    paste("V",seq(p),sep="")))#
## model_check from lasso#
cvfit <- cv.glmnet(x = x, y = y, alpha = 1, maxit = 1e6, family = "binomial")#
tmp <- cvfit$glmnet.fit$beta#
beta.path <- as.matrix(tmp[,cvfit$lambda==cvfit$lambda.min])#
model_check[1, ] <- drop(1 - (beta.path == 0))#
#
## model_check from mcp#
cvfit <- cv.ncvreg(X = x, y = y, penalty = "MCP", family = "binomial", max.iter = 1e6)#
coefit <- cvfit$fit$beta[, cvfit$min]#
model_check[2, ] <- 1 - (coefit[-1] == 0)#
#
## model_check from scad#
cvfit <- cv.ncvreg(X = x, y = y, penalty = "SCAD", family = "binomial", max.iter = 1e6)#
coefit <- cvfit$fit$beta[, cvfit$min]#
model_check[3, ] <- 1 - (coefit[-1] == 0)
n_train = ceiling(n/2)#
no_rep = 100 #
n_train_bound = n_train-2#
n_bound = n-2#
model_check#
psi = 1#
family = "binomial"#
method = "union"#
weight_type = "ARM"#
prior = TRUE#
reduce_bias = FALSE#
    # check data and parameter#
    y <- drop(y)#
    y <- as.numeric(y)#
    x <- as.matrix(x)#
    p <- NCOL(x)#
    n <- length(y)#
    if (family == "binomial") {#
      if (!all(y %in% c(0, 1))) #
        stop("There can only be 0 or 1 in y when using binomial family")#
    }#
    if (n != NROW(x)) #
        stop("x and y have different number of observations")#
    if (n_train >= n) #
        stop("Training size must be less than the number of observations")#
    if (missing(model_check)) #
        stop("User must provide a base model.")#
	if(is.vector(model_check)) model_check <- matrix(model_check,nrow=1)#
    # use union option to compute candidate models#
    if (method == "union") {#
      if (family == "gaussian") #
        candidate_models <- gaussianfit(x, y)#
      if (family == "binomial") #
        candidate_models <- binomialfit(x, y)#
    }#
    if (method == "customize") {#
      if (missing(candidate_models)) #
        stop("Users must supply a candidate model.")#
      if (!is.matrix(candidate_models)) #
        stop("Supplied model must be a matrix.")#
      if (NCOL(candidate_models) != NCOL(x)) #
        stop("Number of variables in candidate model and x does not match.")#
      if (!all(as.numeric(candidate_models) %in% c(0, 1))) #
        stop("There can only be 0 or 1 in candidate_models")#
    }#
    # clean the candidate models#
    candidate_models <- unique(candidate_models)#
    rownames(candidate_models) <- NULL#
    candidate_models <- candidate_models[order(rowSums(candidate_models)), ]#
    if (weight_type == "ARM") {#
      candidate_models <- candidate_models[rowSums(candidate_models) < n_train_bound, ]#
    }else{#
	  candidate_models <- candidate_models[rowSums(candidate_models) < n_bound, ]#
}
type="BIC"#
p <- NCOL(x)#
n <- length(y)#
type <- match.arg(type)#
n_mo <- NROW(candidate_models)#
sk <- rowSums(candidate_models)#
ik <- rep(NA, n_mo)#
if (any(candidate_models[1, ] == 1)) {#
  for (i in seq(n_mo)) {#
    glmfit <- if(reduce_bias==TRUE) brglm(y ~ x[, candidate_models[i, ] == 1], family = binomial) else glm(y ~ x[, candidate_models[i, ] == 1], family = binomial)#
    ik[i] <- if (type == "BIC") extractAIC(glmfit, k=log(n))[2] else extractAIC(glmfit)[2]#
  }   #
} else {#
  glmfit <- if(reduce_bias==TRUE) brglm(y ~ 1, family=binomial) else glm(y ~ 1, family=binomial)#
  ik[1] <- if (type == "BIC") extractAIC(glmfit, k=log(n))[2] else extractAIC(glmfit)[2]#
  for (i in seq(2, n_mo)) {#
    glmfit <- if(reduce_bias==TRUE) brglm(y ~ x[, candidate_models[i, ] == 1], family = binomial) else glm(y ~ x[, candidate_models[i, ] == 1], family = binomial)#
    ik[i] <- if (type == "BIC") extractAIC(glmfit, k=log(n))[2] else extractAIC(glmfit)[2]#
  }#
}#
if (prior == TRUE) {#
  ck <- ck_compute(n_mo, sk, p)#
  ik <- ik + 2 * psi * ck#
}#
ik <- ik - min(ik)#
weight <- exp(-ik/2)/sum(exp(-ik/2))#
list(weight = weight)
candidate_models
no_checkmod <- NROW(model_check)
no_checkmod
VSD <- rep(NA, no_checkmod)
VSD_minus <- rep(NA, no_checkmod)
VSD_plus <- rep(NA, no_checkmod)
model_check
mindex=1
model_check_size[mindex, ]
model_check_size[mindex]
(model_check_size[mindex]-DIFF_minus)
model_check_size <- rowSums(model_check)
model_check_size
candidate_models_size <- rowSums(candidate_models)
mindex=2
TMP_matrix <- sweep(candidate_models, MARGIN = 2, model_check[mindex, ], "-")
DIFF <- rowSums(abs(TMP_matrix))
DIFF_minus <- rowSums(TMP_matrix == -1)
DIFF_plus <- rowSums(TMP_matrix == 1)
model_check_size[mindex]-DIFF_minus
candidate_models_size
(model_check_size[mindex]-DIFF_minus)/candidate_models_size
Prcision <- rep(NA, no_checkmod)
Recall <- rep(NA, no_checkmod)
Fmeasure <- rep(NA, no_checkmod)
Gmeasure <- rep(NA, no_checkmod)
Prcision[mindex] <- (model_check_size[mindex]-DIFF_minus)/model_check_size[mindex]
Prcision[mindex]
(model_check_size[mindex]-DIFF_minus)/model_check_size[mindex]
Prcision <- (model_check_size[mindex]-DIFF_minus)/model_check_size[mindex]
Recall <- (model_check_size[mindex]-DIFF_minus)/candidate_models_size
Prcision
2*(Prcision*Recall)/(Prcision+Recall)
sqrt(Prcision*Recall)
Fmeasure[mindex] <- sum(weight*Fmeasure_tmp)
Fmeasure[mindex]
?sum
Fmeasure_tmp <- 2*(Prcision*Recall)/(Prcision+Recall)
Gmeasure_tmp <- sqrt(Prcision*Recall)
Fmeasure_tmp
Gmeasure_tmp
weight*Fmeasure_tmp
weight*Gmeasure_tmp
sum(weight*Fmeasure_tmp, na.rm = TRUE)
sum(weight*Gmeasure_tmp, na.rm = TRUE)
mindex
VSD[mindex] <- sum(weight*DIFF)  # glmvsd value
VSD[mindex]
VSD_minus[mindex] <- sum(weight*DIFF_minus)  # false positive
VSD_minus[mindex]
VSD_plus[mindex]
no_checkmod <- NROW(model_check)#
VSD <- rep(NA, no_checkmod)#
VSD_minus <- rep(NA, no_checkmod)#
VSD_plus <- rep(NA, no_checkmod)#
Fmeasure <- rep(NA, no_checkmod)#
Gmeasure <- rep(NA, no_checkmod)#
model_check_size <- rowSums(model_check)#
candidate_models_size <- rowSums(candidate_models)#
for (mindex in seq(no_checkmod)) {#
  TMP_matrix <- sweep(candidate_models, MARGIN = 2, model_check[mindex, ], "-")#
  DIFF <- rowSums(abs(TMP_matrix))#
  DIFF_minus <- rowSums(TMP_matrix == -1)#
  DIFF_plus <- rowSums(TMP_matrix == 1)#
  Prcision <- (model_check_size[mindex]-DIFF_minus)/model_check_size[mindex]#
  Recall <- (model_check_size[mindex]-DIFF_minus)/candidate_models_size#
  Fmeasure_tmp <- 2*(Prcision*Recall)/(Prcision+Recall)#
  Gmeasure_tmp <- sqrt(Prcision*Recall)#
  Fmeasure[mindex] <- sum(weight*Fmeasure_tmp, na.rm = TRUE)#
  Gmeasure[mindex] <- sum(weight*Gmeasure_tmp, na.rm = TRUE)#
  VSD[mindex] <- sum(weight*DIFF)  # glmvsd value#
  VSD_minus[mindex] <- sum(weight*DIFF_minus)  # false positive#
  VSD_plus[mindex] <- sum(weight*DIFF_plus)  # false negative #
}
no_checkmod <- NROW(model_check)#
VSD <- rep(NA, no_checkmod)#
VSD_minus <- rep(NA, no_checkmod)#
VSD_plus <- rep(NA, no_checkmod)#
Fmeasure <- rep(NA, no_checkmod)#
Gmeasure <- rep(NA, no_checkmod)#
model_check_size <- rowSums(model_check)#
candidate_models_size <- rowSums(candidate_models)#
for (mindex in seq(no_checkmod)) {#
  # 	#
  TMP_matrix <- sweep(candidate_models, MARGIN = 2, model_check[mindex, ], "-")#
  diff <- rowSums(abs(TMP_matrix))#
  diff_plus <- rowSums(TMP_matrix == 1)#
  diff_minus <- rowSums(TMP_matrix == -1)#
  # compute VSD and VSD plus and minus#
  VSD[mindex] <- sum(weight*diff)  # glmvsd value#
  VSD_plus[mindex] <- sum(weight*diff_plus)  # false negative #
  VSD_minus[mindex] <- sum(weight*diff_minus)  # false positive#
  # compute F measure and G measure using precision and recall#
  Prcision <- (model_check_size[mindex]-diff_minus)/model_check_size[mindex]#
  Recall <- (model_check_size[mindex]-diff_minus)/candidate_models_size#
  Fmeasure_tmp <- 2*(Prcision*Recall)/(Prcision+Recall)#
  Gmeasure_tmp <- sqrt(Prcision*Recall)#
  Fmeasure[mindex] <- sum(weight*Fmeasure_tmp, na.rm = TRUE)#
  Gmeasure[mindex] <- sum(weight*Gmeasure_tmp, na.rm = TRUE)#
}
Fmeasure
Gmeasure
Recall
VSD_minus
VSD_plus
setwd('/Users/yiyang/Dropbox/collaborator/ChenglongYe/debug')
VSD
no_checkmod <- NROW(model_check)#
	  VSD <- rep(NA, no_checkmod)#
	  VSD_minus <- rep(NA, no_checkmod)#
	  VSD_plus <- rep(NA, no_checkmod)#
	  Fmeasure <- rep(NA, no_checkmod)#
	  Gmeasure <- rep(NA, no_checkmod)#
	  # size of m0#
	  model_check_size <- rowSums(model_check)#
	  # size of mk#
	  candidate_models_size <- rowSums(candidate_models)#
	  # start the loop#
	  for (mindex in seq(no_checkmod)) {#
	    # compare m0 and mk#
	    TMP_matrix <- sweep(candidate_models, MARGIN = 2, model_check[mindex, ], "-")#
	    diff <- rowSums(abs(TMP_matrix))#
	    diff_plus <- rowSums(TMP_matrix == 1)#
	    diff_minus <- rowSums(TMP_matrix == -1)#
	    # compute VSD and VSD plus and minus#
	    VSD[mindex] <- sum(weight*diff)  # glmvsd value#
	    VSD_plus[mindex] <- sum(weight*diff_plus)  # false negative #
	    VSD_minus[mindex] <- sum(weight*diff_minus)  # false positive#
	    # compute F measure and G measure using precision and recall#
	    Prcision <- (model_check_size[mindex]-diff_minus)/model_check_size[mindex]#
	    Recall <- (model_check_size[mindex]-diff_minus)/candidate_models_size#
	    Fmeasure_tmp <- 2*(Prcision*Recall)/(Prcision+Recall)#
	    Gmeasure_tmp <- sqrt(Prcision*Recall)#
	    Fmeasure[mindex] <- sum(weight*Fmeasure_tmp, na.rm = TRUE)#
	    Gmeasure[mindex] <- sum(weight*Gmeasure_tmp, na.rm = TRUE)#
	  }
object <- list(VSD = VSD, VSD_minus = VSD_minus, VSD_plus = VSD_plus,  #
	    			Fmeasure = Fmeasure, Gmeasure = Gmeasure,#
                   weight = weight, candidate_models_cleaned = candidate_models)
object <- list(candidate_models_cleaned = candidate_models, VSD = VSD, VSD_minus = VSD_minus, VSD_plus = VSD_plus,  #
	    			Fmeasure = Fmeasure, Gmeasure = Gmeasure,#
                   weight = weight)
setwd('/Users/yiyang/Dropbox/Research/googleproject/glmvsd/R')
object
